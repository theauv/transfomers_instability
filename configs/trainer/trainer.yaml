per_device_train_batch_size: 32
per_device_eval_batch_size: 32
learning_rate: 1e-2
weight_decay: 0.
num_train_epochs: 3
max_train_steps: None
gradient_accumulation_steps: 1
lr_scheduler_type: "linear"
num_warmup_steps: 5000
preprocessing_num_workers: None
